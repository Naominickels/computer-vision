{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from vit_pytorch import ViT\n",
    "from torch.optim import Adam\n",
    "from torch import nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "import os\n",
    "import timm\n",
    "from transformers import AutoFeatureExtractor, AutoModelForImageClassification\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import functional as F\n",
    "from torchview import draw_graph\n",
    "import graphviz\n",
    "from torchsummary import summary\n",
    "from einops import rearrange\n",
    "from PIL import Image\n",
    "graphviz.set_jupyter_format('png')\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [11.7, 8.27]\n",
    "sns.set_theme(style='white')\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "\n",
    "device = torch.device('cuda')\n",
    "HF_MODEL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import beta\n",
    "import torch\n",
    "\n",
    "\n",
    "def fftfreqnd(h, w=None, z=None):\n",
    "    \"\"\" Get bin values for discrete fourier transform of size (h, w, z)\n",
    "\n",
    "    :param h: Required, first dimension size\n",
    "    :param w: Optional, second dimension size\n",
    "    :param z: Optional, third dimension size\n",
    "    \"\"\"\n",
    "    fz = fx = 0\n",
    "    fy = np.fft.fftfreq(h)\n",
    "\n",
    "    if w is not None:\n",
    "        fy = np.expand_dims(fy, -1)\n",
    "\n",
    "        if w % 2 == 1:\n",
    "            fx = np.fft.fftfreq(w)[: w // 2 + 2]\n",
    "        else:\n",
    "            fx = np.fft.fftfreq(w)[: w // 2 + 1]\n",
    "\n",
    "    if z is not None:\n",
    "        fy = np.expand_dims(fy, -1)\n",
    "        if z % 2 == 1:\n",
    "            fz = np.fft.fftfreq(z)[:, None]\n",
    "        else:\n",
    "            fz = np.fft.fftfreq(z)[:, None]\n",
    "\n",
    "    return np.sqrt(fx * fx + fy * fy + fz * fz)\n",
    "\n",
    "\n",
    "def get_spectrum(freqs, decay_power, ch, h, w=0, z=0):\n",
    "    \"\"\" Samples a fourier image with given size and frequencies decayed by decay power\n",
    "\n",
    "    :param freqs: Bin values for the discrete fourier transform\n",
    "    :param decay_power: Decay power for frequency decay prop 1/f**d\n",
    "    :param ch: Number of channels for the resulting mask\n",
    "    :param h: Required, first dimension size\n",
    "    :param w: Optional, second dimension size\n",
    "    :param z: Optional, third dimension size\n",
    "    \"\"\"\n",
    "    scale = np.ones(1) / (np.maximum(freqs, np.array([1. / max(w, h, z)])) ** decay_power)\n",
    "\n",
    "    param_size = [ch] + list(freqs.shape) + [2]\n",
    "    param = np.random.randn(*param_size)\n",
    "\n",
    "    scale = np.expand_dims(scale, -1)[None, :]\n",
    "\n",
    "    return scale * param\n",
    "\n",
    "\n",
    "def make_low_freq_image(decay, shape, ch=1):\n",
    "    \"\"\" Sample a low frequency image from fourier space\n",
    "\n",
    "    :param decay_power: Decay power for frequency decay prop 1/f**d\n",
    "    :param shape: Shape of desired mask, list up to 3 dims\n",
    "    :param ch: Number of channels for desired mask\n",
    "    \"\"\"\n",
    "    freqs = fftfreqnd(*shape)\n",
    "    spectrum = get_spectrum(freqs, decay, ch, *shape)#.reshape((1, *shape[:-1], -1))\n",
    "    spectrum = spectrum[:, 0] + 1j * spectrum[:, 1]\n",
    "    mask = np.real(np.fft.irfftn(spectrum, shape))\n",
    "\n",
    "    if len(shape) == 1:\n",
    "        mask = mask[:1, :shape[0]]\n",
    "    if len(shape) == 2:\n",
    "        mask = mask[:1, :shape[0], :shape[1]]\n",
    "    if len(shape) == 3:\n",
    "        mask = mask[:1, :shape[0], :shape[1], :shape[2]]\n",
    "\n",
    "    mask = mask\n",
    "    mask = (mask - mask.min())\n",
    "    mask = mask / mask.max()\n",
    "    return mask\n",
    "\n",
    "\n",
    "def sample_lam(alpha, reformulate=False):\n",
    "    \"\"\" Sample a lambda from symmetric beta distribution with given alpha\n",
    "\n",
    "    :param alpha: Alpha value for beta distribution\n",
    "    :param reformulate: If True, uses the reformulation of [1].\n",
    "    \"\"\"\n",
    "    if reformulate:\n",
    "        lam = beta.rvs(alpha+1, alpha)\n",
    "    else:\n",
    "        lam = beta.rvs(alpha, alpha)\n",
    "\n",
    "    return lam\n",
    "\n",
    "\n",
    "def binarise_mask(mask, lam, in_shape, max_soft=0.0):\n",
    "    \"\"\" Binarises a given low frequency image such that it has mean lambda.\n",
    "\n",
    "    :param mask: Low frequency image, usually the result of `make_low_freq_image`\n",
    "    :param lam: Mean value of final mask\n",
    "    :param in_shape: Shape of inputs\n",
    "    :param max_soft: Softening value between 0 and 0.5 which smooths hard edges in the mask.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    idx = mask.reshape(-1).argsort()[::-1]\n",
    "    mask = mask.reshape(-1)\n",
    "    num = math.ceil(lam * mask.size) if random.random() > 0.5 else math.floor(lam * mask.size)\n",
    "\n",
    "    eff_soft = max_soft\n",
    "    if max_soft > lam or max_soft > (1-lam):\n",
    "        eff_soft = min(lam, 1-lam)\n",
    "\n",
    "    soft = int(mask.size * eff_soft)\n",
    "    num_low = num - soft\n",
    "    num_high = num + soft\n",
    "\n",
    "    mask[idx[:num_high]] = 1\n",
    "    mask[idx[num_low:]] = 0\n",
    "    mask[idx[num_low:num_high]] = np.linspace(1, 0, (num_high - num_low))\n",
    "\n",
    "    mask = mask.reshape((1, *in_shape))\n",
    "    return mask\n",
    "\n",
    "\n",
    "def sample_mask(alpha, decay_power, shape, max_soft=0.0, reformulate=False):\n",
    "    \"\"\" Samples a mean lambda from beta distribution parametrised by alpha, creates a low frequency image and binarises\n",
    "    it based on this lambda\n",
    "\n",
    "    :param alpha: Alpha value for beta distribution from which to sample mean of mask\n",
    "    :param decay_power: Decay power for frequency decay prop 1/f**d\n",
    "    :param shape: Shape of desired mask, list up to 3 dims\n",
    "    :param max_soft: Softening value between 0 and 0.5 which smooths hard edges in the mask.\n",
    "    :param reformulate: If True, uses the reformulation of [1].\n",
    "    \"\"\"\n",
    "    if isinstance(shape, int):\n",
    "        shape = (shape,)\n",
    "\n",
    "    # Choose lambda\n",
    "    lam = sample_lam(alpha, reformulate)\n",
    "\n",
    "    # Make mask, get mean / std\n",
    "    mask = make_low_freq_image(decay_power, shape)\n",
    "    mask = binarise_mask(mask, lam, shape, max_soft)\n",
    "\n",
    "    return lam, mask\n",
    "\n",
    "\n",
    "def sample_and_apply(x, alpha, decay_power, shape, max_soft=0.0, reformulate=False):\n",
    "\t\"\"\"\n",
    "\n",
    "\t:param x: Image batch on which to apply fmix of shape [b, c, shape*]\n",
    "\t:param alpha: Alpha value for beta distribution from which to sample mean of mask\n",
    "\t:param decay_power: Decay power for frequency decay prop 1/f**d\n",
    "\t:param shape: Shape of desired mask, list up to 3 dims\n",
    "\t:param max_soft: Softening value between 0 and 0.5 which smooths hard edges in the mask.\n",
    "\t:param reformulate: If True, uses the reformulation of [1].\n",
    "\t:return: mixed input, permutation indices, lambda value of mix,\n",
    "\t\"\"\"\n",
    "\tlam, mask = sample_mask(alpha, decay_power, shape, max_soft, reformulate)\n",
    "\tindex = np.random.permutation(x.shape[0])\n",
    "\n",
    "\tx1, x2 = x * mask, x[index] * (1-mask)\n",
    "\treturn x1+x2, index, lam\n",
    "\n",
    "\n",
    "class FMix:\n",
    "\tr\"\"\" FMix augmentation\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\tdecay_power (float): Decay power for frequency decay prop 1/f**d\n",
    "\t\t\talpha (float): Alpha value for beta distribution from which to sample mean of mask\n",
    "\t\t\tsize ([int] | [int, int] | [int, int, int]): Shape of desired mask, list up to 3 dims\n",
    "\t\t\tmax_soft (float): Softening value between 0 and 0.5 which smooths hard edges in the mask.\n",
    "\t\t\treformulate (bool): If True, uses the reformulation of [1].\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self, decay_power=3, alpha=1, size=(32, 32), max_soft=0.0, reformulate=False):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.decay_power = decay_power\n",
    "\t\tself.reformulate = reformulate\n",
    "\t\tself.size = size\n",
    "\t\tself.alpha = alpha\n",
    "\t\tself.max_soft = max_soft\n",
    "\t\tself.index = None\n",
    "\t\tself.lam = None\n",
    "  \n",
    "\tdef __call__(self, x):\n",
    "\t\tx = x.cpu().numpy()\n",
    "\t\tx, index, lam = sample_and_apply(x, self.alpha, self.decay_power, self.size, self.max_soft, self.reformulate)\n",
    "\t\tx = torch.Tensor(x)\n",
    "\t\treturn x, index, lam\n",
    "\n",
    "\tdef loss(self, *args, **kwargs):\n",
    "\t\traise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timm.list_models(filter = \"*vit_small_patch16*\", pretrained = True)\n",
    "model_name = 'vit_small_patch16_224.augreg_in21k'\n",
    "organistation = 'google' # For HF models\n",
    "image1_name = '../datasets/augmented/images/train/happy/25.jpg'\n",
    "image2_name = '../datasets/augmented/images/train/disgust/synthetic_0.jpg'\n",
    "num_classes = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not HF_MODEL:\n",
    "    model = timm.create_model(model_name, pretrained = True, num_classes = num_classes, drop_rate = 0.1).to(device)\n",
    "    timm_data_config = timm.data.resolve_data_config({}, model = model)\n",
    "    processor = transforms.Normalize(mean = timm_data_config['mean'], std = timm_data_config['std'])\n",
    "else:\n",
    "    # processor = transforms.Normalize(mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225))\n",
    "    # processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "    processor = transforms.Normalize(mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5))\n",
    "\n",
    "def transform_images(x):\n",
    "    x = x.resize((224, 224))\n",
    "    x = transforms.ToTensor()(x)\n",
    "    \n",
    "    # for some weird reason here it needs to be extended to 3 channels\n",
    "    if x.shape[0] == 1:\n",
    "        x = x.repeat(3, 1, 1)\n",
    "    x = processor(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(x, y):\n",
    "    lam = np.random.beta(0.8, 0.8)\n",
    "    indices = torch.Tensor([1, 0]).long()\n",
    "        \n",
    "    shuffled_x = x[indices]\n",
    "    shuffled_y = y[indices]\n",
    "    \n",
    "    new_x = x * lam + shuffled_x * (1 - lam)\n",
    "    new_y = y * lam + shuffled_y * (1 - lam)\n",
    "    \n",
    "    return new_x, new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W // 4, W - W // 4)\n",
    "    cy = np.random.randint(H // 4, H - H // 4)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "def cutmix(x, y):\n",
    "    lam = np.random.beta(0.8, 0.8)\n",
    "    indices = torch.randperm(x.shape[0])\n",
    "    \n",
    "    shuffled_x = x[indices]\n",
    "    shuffled_y = y[indices]\n",
    "  \n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.shape, lam)\n",
    "    x[:, :, bbx1:bbx2, bby1:bby2] = shuffled_x[:, :, bbx1:bbx2, bby1:bby2]\n",
    "    # adjust lambda to exactly match pixel ratio\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.shape[-1] * x.shape[-2]))\n",
    "    new_y = y * lam + shuffled_y * (1 - lam)\n",
    " \n",
    "    #plt.imshow(x[0].permute(1, 2, 0) / 2 + 0.5)\n",
    "    #plt.show()\n",
    "\n",
    "    return x, new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutout(x, y):\n",
    "    lam = np.random.beta(0.8, 0.8)\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.shape, lam)\n",
    "    \n",
    "    x[:, :, bbx1:bbx2, bby1:bby2] = 0\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmix(x, y):\n",
    "    new_x, index, lam = FMix(size = x.shape[2 :])(x)\n",
    "    new_y = y * lam + y[index] * (1 - lam)\n",
    "    \n",
    "    return new_x.to(device), new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_functions = {'mixup': mixup, 'cutmix': cutmix, 'cutout': cutout, 'fmix': fmix}\n",
    "# Change function here\n",
    "used_aug_function = 'cutout'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not HF_MODEL:\n",
    "    model = timm.create_model(model_name, pretrained = True, num_classes = num_classes, drop_rate = 0.1).to(device)\n",
    "else:\n",
    "    model = AutoModelForImageClassification.from_pretrained(model_name, num_labels = num_classes, ignore_mismatched_sizes = True).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(f'../fer/saved_models/{model_name}_full.pth'))\n",
    "model.eval()\n",
    "classifier = model.get_classifier()\n",
    "print(classifier.weight.shape)\n",
    "\n",
    "#print(type(model))\n",
    "#timm.models.vision_transformer.VisionTransformer\n",
    "\n",
    "with torch.no_grad():\n",
    "    image1 = Image.open(image1_name)\n",
    "    image1 = transform_images(image1)[None, :]\n",
    "    image1 = image1.to(device)\n",
    "    \n",
    "    image2 = Image.open(image2_name)\n",
    "    image2 = transform_images(image2)[None, :]\n",
    "    image2 = image2.to(device)\n",
    "    \n",
    "    x = torch.concat([image1, image2])\n",
    "    \n",
    "    x, y = augmentation_functions[used_aug_function](x, torch.zeros(2))\n",
    "    image = x[0:1]\n",
    "    \n",
    "    if not HF_MODEL:\n",
    "        feats = model.forward_features(image)\n",
    "        out = model.forward_head(feats)\n",
    "        print(out)\n",
    "        class_out = torch.argmax(out, 1).item()\n",
    "        weights = classifier.weight[class_out]\n",
    "    \n",
    "    feats = feats[:, 1:, :]\n",
    "    feats = rearrange(feats, 'b (h w) c -> b c h w', h = 14, w = 14)\n",
    "    \n",
    "    cam = torch.zeros((feats.shape[-1], feats.shape[-1])).to(device)\n",
    "    for feat, weight in zip(feats[0], weights):\n",
    "        cam += feat * weight\n",
    "    \n",
    "    cam = transforms.Resize((224, 224), interpolation=transforms.InterpolationMode.BICUBIC)(cam[None, :])[0]\n",
    "    cam = ((cam - cam.min()) / (cam.max() - cam.min())).cpu()\n",
    "    cam = plt.cm.jet(cam)[:, :, :3]\n",
    "    image = (image[0] * 0.5 + 0.5).permute(1, 2, 0).cpu()\n",
    "    \n",
    "    #plt.imshow(image * 0.5 + cam * 0.5)\n",
    "    _, ax = plt.subplots(1, 2)\n",
    "    ax[0].axis('off')\n",
    "    ax[0].imshow(image)\n",
    "    ax[1].axis('off')\n",
    "    ax[1].imshow(image * 0.5 + cam * 0.5)\n",
    "    \n",
    "    # for module_name in model._modules:\n",
    "    #     module = model._modules[module_name]\n",
    "    #     print(x.shape)\n",
    "    #     x = module(x)\n",
    "    #     print(f\"After going through {module_name}: {x.shape}\")\n",
    "if not os.path.exists('saved_images'):\n",
    "    os.makedirs('saved_images')\n",
    "plt.savefig(f'saved_images/cam-{used_aug_function}2.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

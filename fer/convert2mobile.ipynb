{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "from os.path import join\n",
    "from transformers import AutoFeatureExtractor, AutoModelForImageClassification, AutoImageProcessor\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "HF_MODEL = True\n",
    "CONVERT_FEATS = True\n",
    "OPTIMIZE = False # Optimization most of the time messes up models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'mobilenet_v2_0.75_160'\n",
    "organistation = 'google' # For HF models\n",
    "num_classes = 7\n",
    "MODELS_PATH = 'saved_models'\n",
    "# IMAGE_SIZE = 384\n",
    "#IMAGE_SIZE = 256\n",
    "# IMAGE_SIZE = 224\n",
    "IMAGE_SIZE = 160\n",
    "# X = np.ones((IMAGE_SIZE, IMAGE_SIZE, 3)) * 255\n",
    "# X = Image.fromarray(X.astype('uint8')).convert('RGB')\n",
    "# processor = AutoFeatureExtractor.from_pretrained('microsoft/' + model_name)\n",
    "# print(processor)\n",
    "# processor(X)['pixel_values'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Helper(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).logits\n",
    "\n",
    "if not HF_MODEL:\n",
    "    model_full = timm.create_model(model_name, pretrained = True, num_classes = num_classes, drop_rate = 0.1)\n",
    "    model_full.train()\n",
    "    if CONVERT_FEATS:\n",
    "        model_feats = timm.create_model(model_name, pretrained = True, num_classes = 0, drop_rate = 0.1)\n",
    "        model_feats.eval()\n",
    "    timm_data_config = timm.data.resolve_data_config({}, model=model_full)\n",
    "    print(timm_data_config)\n",
    "else:\n",
    "    model_full = AutoModelForImageClassification.from_pretrained(organistation + '/' + model_name, num_labels = num_classes, ignore_mismatched_sizes = True)\n",
    "    model_full.train()\n",
    "    helper = Helper(model_full)\n",
    "    if CONVERT_FEATS:\n",
    "        model_feats = AutoModelForImageClassification.from_pretrained(organistation + '/' + model_name, num_labels = 0, ignore_mismatched_sizes = True)\n",
    "        model_feats.eval()\n",
    "        helper_feats = Helper(model_feats)\n",
    "        \n",
    "model_full.load_state_dict(torch.load(join(MODELS_PATH, model_name + '_full.pth')))\n",
    "if CONVERT_FEATS:\n",
    "    print('Loading features model')\n",
    "    model_feats.load_state_dict(torch.load(join(MODELS_PATH, model_name + '_feats.pth')))\n",
    "\n",
    "X = torch.distributions.uniform.Uniform(0, 1).sample((1, 3, IMAGE_SIZE, IMAGE_SIZE))\n",
    "if not HF_MODEL:\n",
    "    processor = transforms.Normalize(mean = timm_data_config['mean'], std = timm_data_config['std'])\n",
    "else:\n",
    "    # processor = transforms.Normalize(mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225))\n",
    "    processor = transforms.Normalize(mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5))\n",
    "\n",
    "X = processor(X)\n",
    "\n",
    "if not HF_MODEL:\n",
    "    dropout_traced_script = torch.jit.trace(model_full, X)\n",
    "    model_full.eval()\n",
    "    classifier_traced_script = torch.jit.trace(model_full, X)\n",
    "    if CONVERT_FEATS:\n",
    "        feature_traced_script = torch.jit.trace(model_feats, X)\n",
    "else:\n",
    "    dropout_traced_script = torch.jit.trace(helper, X)\n",
    "    model_full.eval()\n",
    "    classifier_traced_script = torch.jit.trace(helper, X)\n",
    "    if CONVERT_FEATS:\n",
    "        feature_traced_script = torch.jit.trace(helper_feats, X)\n",
    "\n",
    "if OPTIMIZE:\n",
    "    if CONVERT_FEATS:\n",
    "        feature_traced_script = optimize_for_mobile(feature_traced_script)\n",
    "    dropout_traced_script = optimize_for_mobile(dropout_traced_script)\n",
    "    classifier_traced_script = optimize_for_mobile(classifier_traced_script)\n",
    "\n",
    "if CONVERT_FEATS:\n",
    "    feature_traced_script.save(join(MODELS_PATH, model_name + '_feats_mobile.pt'))\n",
    "dropout_traced_script.save(join(MODELS_PATH, model_name + '_dropout_mobile.pt'))\n",
    "classifier_traced_script.save(join(MODELS_PATH, model_name + '_full_mobile.pt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

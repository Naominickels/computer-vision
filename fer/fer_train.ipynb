{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T22:44:45.322221Z","iopub.status.busy":"2024-05-19T22:44:45.321528Z","iopub.status.idle":"2024-05-19T22:45:16.413822Z","shell.execute_reply":"2024-05-19T22:45:16.413030Z","shell.execute_reply.started":"2024-05-19T22:44:45.322193Z"},"trusted":true},"outputs":[],"source":["!pip install torchinfo\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","from torch.optim import Adam\n","from torch import nn as nn\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import precision_recall_fscore_support\n","from sklearn.metrics import top_k_accuracy_score\n","import os\n","import timm\n","from transformers import AutoFeatureExtractor, AutoModelForImageClassification, AutoImageProcessor\n","from torch.utils.data import Dataset\n","from torchvision.transforms import functional as F\n","import graphviz\n","from torchinfo import summary\n","graphviz.set_jupyter_format('png')\n","\n","%matplotlib inline\n","plt.rcParams['figure.figsize'] = [11.7, 8.27]\n","sns.set_theme(style='white')\n","pd.set_option(\"display.precision\", 3)\n","\n","device = torch.device('cuda')\n","\n","HF_MODEL = True"]},{"cell_type":"markdown","metadata":{},"source":["### FMix Implementation\n","Taken from https://github.com/ecs-vlc/FMix"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T22:45:16.416026Z","iopub.status.busy":"2024-05-19T22:45:16.415479Z","iopub.status.idle":"2024-05-19T22:45:16.444043Z","shell.execute_reply":"2024-05-19T22:45:16.443126Z","shell.execute_reply.started":"2024-05-19T22:45:16.415993Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["import math\n","import random\n","\n","import numpy as np\n","from scipy.stats import beta\n","import torch\n","\n","\n","def fftfreqnd(h, w=None, z=None):\n","    \"\"\" Get bin values for discrete fourier transform of size (h, w, z)\n","\n","    :param h: Required, first dimension size\n","    :param w: Optional, second dimension size\n","    :param z: Optional, third dimension size\n","    \"\"\"\n","    fz = fx = 0\n","    fy = np.fft.fftfreq(h)\n","\n","    if w is not None:\n","        fy = np.expand_dims(fy, -1)\n","\n","        if w % 2 == 1:\n","            fx = np.fft.fftfreq(w)[: w // 2 + 2]\n","        else:\n","            fx = np.fft.fftfreq(w)[: w // 2 + 1]\n","\n","    if z is not None:\n","        fy = np.expand_dims(fy, -1)\n","        if z % 2 == 1:\n","            fz = np.fft.fftfreq(z)[:, None]\n","        else:\n","            fz = np.fft.fftfreq(z)[:, None]\n","\n","    return np.sqrt(fx * fx + fy * fy + fz * fz)\n","\n","\n","def get_spectrum(freqs, decay_power, ch, h, w=0, z=0):\n","    \"\"\" Samples a fourier image with given size and frequencies decayed by decay power\n","\n","    :param freqs: Bin values for the discrete fourier transform\n","    :param decay_power: Decay power for frequency decay prop 1/f**d\n","    :param ch: Number of channels for the resulting mask\n","    :param h: Required, first dimension size\n","    :param w: Optional, second dimension size\n","    :param z: Optional, third dimension size\n","    \"\"\"\n","    scale = np.ones(1) / (np.maximum(freqs, np.array([1. / max(w, h, z)])) ** decay_power)\n","\n","    param_size = [ch] + list(freqs.shape) + [2]\n","    param = np.random.randn(*param_size)\n","\n","    scale = np.expand_dims(scale, -1)[None, :]\n","\n","    return scale * param\n","\n","\n","def make_low_freq_image(decay, shape, ch=1):\n","    \"\"\" Sample a low frequency image from fourier space\n","\n","    :param decay_power: Decay power for frequency decay prop 1/f**d\n","    :param shape: Shape of desired mask, list up to 3 dims\n","    :param ch: Number of channels for desired mask\n","    \"\"\"\n","    freqs = fftfreqnd(*shape)\n","    spectrum = get_spectrum(freqs, decay, ch, *shape)#.reshape((1, *shape[:-1], -1))\n","    spectrum = spectrum[:, 0] + 1j * spectrum[:, 1]\n","    mask = np.real(np.fft.irfftn(spectrum, shape))\n","\n","    if len(shape) == 1:\n","        mask = mask[:1, :shape[0]]\n","    if len(shape) == 2:\n","        mask = mask[:1, :shape[0], :shape[1]]\n","    if len(shape) == 3:\n","        mask = mask[:1, :shape[0], :shape[1], :shape[2]]\n","\n","    mask = mask\n","    mask = (mask - mask.min())\n","    mask = mask / mask.max()\n","    return mask\n","\n","\n","def sample_lam(alpha, reformulate=False):\n","    \"\"\" Sample a lambda from symmetric beta distribution with given alpha\n","\n","    :param alpha: Alpha value for beta distribution\n","    :param reformulate: If True, uses the reformulation of [1].\n","    \"\"\"\n","    if reformulate:\n","        lam = beta.rvs(alpha+1, alpha)\n","    else:\n","        lam = beta.rvs(alpha, alpha)\n","\n","    return lam\n","\n","\n","def binarise_mask(mask, lam, in_shape, max_soft=0.0):\n","    \"\"\" Binarises a given low frequency image such that it has mean lambda.\n","\n","    :param mask: Low frequency image, usually the result of `make_low_freq_image`\n","    :param lam: Mean value of final mask\n","    :param in_shape: Shape of inputs\n","    :param max_soft: Softening value between 0 and 0.5 which smooths hard edges in the mask.\n","    :return:\n","    \"\"\"\n","    idx = mask.reshape(-1).argsort()[::-1]\n","    mask = mask.reshape(-1)\n","    num = math.ceil(lam * mask.size) if random.random() > 0.5 else math.floor(lam * mask.size)\n","\n","    eff_soft = max_soft\n","    if max_soft > lam or max_soft > (1-lam):\n","        eff_soft = min(lam, 1-lam)\n","\n","    soft = int(mask.size * eff_soft)\n","    num_low = num - soft\n","    num_high = num + soft\n","\n","    mask[idx[:num_high]] = 1\n","    mask[idx[num_low:]] = 0\n","    mask[idx[num_low:num_high]] = np.linspace(1, 0, (num_high - num_low))\n","\n","    mask = mask.reshape((1, *in_shape))\n","    return mask\n","\n","\n","def sample_mask(alpha, decay_power, shape, max_soft=0.0, reformulate=False):\n","    \"\"\" Samples a mean lambda from beta distribution parametrised by alpha, creates a low frequency image and binarises\n","    it based on this lambda\n","\n","    :param alpha: Alpha value for beta distribution from which to sample mean of mask\n","    :param decay_power: Decay power for frequency decay prop 1/f**d\n","    :param shape: Shape of desired mask, list up to 3 dims\n","    :param max_soft: Softening value between 0 and 0.5 which smooths hard edges in the mask.\n","    :param reformulate: If True, uses the reformulation of [1].\n","    \"\"\"\n","    if isinstance(shape, int):\n","        shape = (shape,)\n","\n","    # Choose lambda\n","    lam = sample_lam(alpha, reformulate)\n","\n","    # Make mask, get mean / std\n","    mask = make_low_freq_image(decay_power, shape)\n","    mask = binarise_mask(mask, lam, shape, max_soft)\n","\n","    return lam, mask\n","\n","\n","def sample_and_apply(x, alpha, decay_power, shape, max_soft=0.0, reformulate=False):\n","\t\"\"\"\n","\n","\t:param x: Image batch on which to apply fmix of shape [b, c, shape*]\n","\t:param alpha: Alpha value for beta distribution from which to sample mean of mask\n","\t:param decay_power: Decay power for frequency decay prop 1/f**d\n","\t:param shape: Shape of desired mask, list up to 3 dims\n","\t:param max_soft: Softening value between 0 and 0.5 which smooths hard edges in the mask.\n","\t:param reformulate: If True, uses the reformulation of [1].\n","\t:return: mixed input, permutation indices, lambda value of mix,\n","\t\"\"\"\n","\tlam, mask = sample_mask(alpha, decay_power, shape, max_soft, reformulate)\n","\tindex = np.random.permutation(x.shape[0])\n","\n","\tx1, x2 = x * mask, x[index] * (1-mask)\n","\treturn x1+x2, index, lam\n","\n","\n","class FMix:\n","\tr\"\"\" FMix augmentation\n","\n","\t\tArgs:\n","\t\t\tdecay_power (float): Decay power for frequency decay prop 1/f**d\n","\t\t\talpha (float): Alpha value for beta distribution from which to sample mean of mask\n","\t\t\tsize ([int] | [int, int] | [int, int, int]): Shape of desired mask, list up to 3 dims\n","\t\t\tmax_soft (float): Softening value between 0 and 0.5 which smooths hard edges in the mask.\n","\t\t\treformulate (bool): If True, uses the reformulation of [1].\n","\t\"\"\"\n","\n","\tdef __init__(self, decay_power=3, alpha=1, size=(32, 32), max_soft=0.0, reformulate=False):\n","\t\tsuper().__init__()\n","\t\tself.decay_power = decay_power\n","\t\tself.reformulate = reformulate\n","\t\tself.size = size\n","\t\tself.alpha = alpha\n","\t\tself.max_soft = max_soft\n","\t\tself.index = None\n","\t\tself.lam = None\n","  \n","\tdef __call__(self, x):\n","\t\tx = x.cpu().numpy()\n","\t\tx, index, lam = sample_and_apply(x, self.alpha, self.decay_power, self.size, self.max_soft, self.reformulate)\n","\t\tx = torch.Tensor(x)\n","\t\treturn x, index, lam\n","\n","\tdef loss(self, *args, **kwargs):\n","\t\traise NotImplementedError"]},{"cell_type":"markdown","metadata":{},"source":["### Hyperparams"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T22:45:16.445265Z","iopub.status.busy":"2024-05-19T22:45:16.445015Z","iopub.status.idle":"2024-05-19T22:45:16.484124Z","shell.execute_reply":"2024-05-19T22:45:16.483110Z","shell.execute_reply.started":"2024-05-19T22:45:16.445243Z"},"trusted":true},"outputs":[],"source":["timm.list_models(filter = \"*vit_small_patch16*\", pretrained = True)\n","# model_name = 'tiny_vit_5m_224.dist_in22k_ft_in1k'\n","# model_name = 'vit_small_patch16_224.augreg_in21k'\n","model_name = 'google/mobilenet_v2_0.75_160'\n","num_classes = 7\n","batch_size = 32\n","num_epochs = 25\n","learning_rate = 0.0002\n","online_augmentation_function = None # Possible values: None, 'fmix', 'cutmix, 'mixup', 'cutout'"]},{"cell_type":"markdown","metadata":{},"source":["### Train function"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T22:45:16.486633Z","iopub.status.busy":"2024-05-19T22:45:16.486340Z","iopub.status.idle":"2024-05-19T22:45:16.505505Z","shell.execute_reply":"2024-05-19T22:45:16.504474Z","shell.execute_reply.started":"2024-05-19T22:45:16.486608Z"},"trusted":true},"outputs":[],"source":["num_to_class = {}\n","\n","def calculate_loss(model, criterion, test):\n","    with torch.no_grad():\n","        losses = []\n","        for features, labels in test:\n","            features = features.to(device)\n","            labels = labels.to(device)\n","            \n","            if not HF_MODEL:\n","                y = model(features)\n","            else:\n","                y = model(features).logits\n","            loss = criterion(y, labels)\n","            losses.append(loss.item())\n","        return np.mean(losses)\n","\n","def predict_multiple(model, test):\n","    with torch.no_grad():\n","        outputs_raw = []\n","        outputs = []\n","        golden = []\n","        for features, labels in test:\n","            features = features.to(device)\n","            \n","            if not HF_MODEL:\n","                y = model(features)\n","            else:\n","                y = model(features).logits\n","            \n","            outputs_raw.append(y.cpu().numpy())\n","            outputs.append(torch.argmax(y, dim = 1).cpu().numpy())\n","            golden.append(labels.numpy())\n","        return np.concatenate(golden), np.concatenate(outputs), np.concatenate(outputs_raw)\n","\n","def train_network(model : nn.Module, optimizer : torch.optim.Optimizer, criterion, train, test, epochs = 50, use_scheduler = True):\n","    if use_scheduler:\n","       scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 30, 45, 60, 75, 90], gamma=0.25)\n","    \n","    train_losses = []\n","    test_losses = []\n","    \n","    table = {'Accuracy': [], 'Accuracy-2': []}\n","    for label in range(num_classes):\n","        table['Precision ' + num_to_class[label]] = []\n","        table['Recall ' + num_to_class[label]] = []\n","        table['F1 ' + num_to_class[label]] = []\n","    \n","    for epoch in range(1, epochs + 1):\n","        epoch_train_losses = []\n","        \n","        for features, labels in train:\n","            features = features.to(device)\n","            labels = labels.to(device)\n","            \n","            if not HF_MODEL:\n","                y = model(features)\n","            else:\n","                y = model(features).logits\n","            loss = criterion(y, labels)\n","            model.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            epoch_train_losses.append(loss.item())\n","        \n","        train_losses.append(np.mean(epoch_train_losses))\n","        test_losses.append(calculate_loss(model, criterion, test))\n","        \n","        golden, outputs, outputs_raw = predict_multiple(model, test)\n","        \n","        prfs = precision_recall_fscore_support(golden, outputs, zero_division = 0)\n","        \n","        table['Accuracy'].append(accuracy_score(golden, outputs))\n","        table['Accuracy-2'].append(top_k_accuracy_score(golden, outputs_raw, k = 2))\n","        for i, label in enumerate(range(num_classes)):\n","            table['Precision ' + num_to_class[label]].append(prfs[0][i])\n","            table['Recall ' + num_to_class[label]].append(prfs[1][i])\n","            table['F1 ' + num_to_class[label]].append(prfs[2][i])\n","        \n","        last_acc = table['Accuracy'][-1]\n","        last_acc_2 = table['Accuracy-2'][-1]\n","        print(f'Epoch {epoch}: Train loss {train_losses[-1]}, Test loss {test_losses[-1]}, Test acc {last_acc}, Test acc-2 {last_acc_2}')\n","            \n","        if use_scheduler:\n","            scheduler.step()\n","    \n","    return train_losses, test_losses, table\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T22:45:16.506983Z","iopub.status.busy":"2024-05-19T22:45:16.506642Z","iopub.status.idle":"2024-05-19T22:45:18.939519Z","shell.execute_reply":"2024-05-19T22:45:18.938612Z","shell.execute_reply.started":"2024-05-19T22:45:16.506951Z"},"trusted":true},"outputs":[],"source":["if not HF_MODEL:\n","    model = timm.create_model(model_name, pretrained = True, num_classes = num_classes, drop_rate = 0.1).to(device)\n","    timm_data_config = timm.data.resolve_data_config({}, model=model)\n","    print(timm_data_config)\n","else:\n","    model = AutoModelForImageClassification.from_pretrained(model_name, num_labels = num_classes, ignore_mismatched_sizes = True).to(device)"]},{"cell_type":"markdown","metadata":{},"source":["###"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T22:45:18.941197Z","iopub.status.busy":"2024-05-19T22:45:18.940798Z","iopub.status.idle":"2024-05-19T22:45:18.951863Z","shell.execute_reply":"2024-05-19T22:45:18.950983Z","shell.execute_reply.started":"2024-05-19T22:45:18.941160Z"},"trusted":true},"outputs":[],"source":["if not HF_MODEL:\n","    processor = transforms.Normalize(mean = timm_data_config['mean'], std = timm_data_config['std'])\n","else:\n","#     processor = transforms.Normalize(mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225))\n","#     processor = AutoImageProcessor.from_pretrained(model_name)\n","      processor = transforms.Normalize(mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5))\n","\n","def transform_images(x):\n","    x = x.resize((160, 160))\n","    x = transforms.ToTensor()(x)\n","    # x = transforms.RandomRotation(180)(x)\n","    x = transforms.RandomHorizontalFlip(0.5)(x)\n","    # x = transforms.RandomHorizontalFlip(0.25)(x)\n","    # x = transforms.RandomVerticalFlip(0.25)(x)\n","    x = processor(x)\n","    return x\n","\n","processor"]},{"cell_type":"markdown","metadata":{},"source":["### Mixup"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T22:45:18.953648Z","iopub.status.busy":"2024-05-19T22:45:18.953281Z","iopub.status.idle":"2024-05-19T22:45:18.966818Z","shell.execute_reply":"2024-05-19T22:45:18.965994Z","shell.execute_reply.started":"2024-05-19T22:45:18.953622Z"},"trusted":true},"outputs":[],"source":["def mixup(x, y):\n","    lam = np.random.beta(0.8, 0.8)\n","    indices = torch.randperm(x.shape[0])\n","        \n","    shuffled_x = x[indices]\n","    shuffled_y = y[indices]\n","    \n","    new_x = x * lam + shuffled_x * (1 - lam)\n","    new_y = y * lam + shuffled_y * (1 - lam)\n","    \n","    return new_x, new_y"]},{"cell_type":"markdown","metadata":{},"source":["### Cutmix"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T22:45:18.968075Z","iopub.status.busy":"2024-05-19T22:45:18.967778Z","iopub.status.idle":"2024-05-19T22:45:18.980790Z","shell.execute_reply":"2024-05-19T22:45:18.979841Z","shell.execute_reply.started":"2024-05-19T22:45:18.968051Z"},"trusted":true},"outputs":[],"source":["def rand_bbox(size, lam):\n","    W = size[2]\n","    H = size[3]\n","    cut_rat = np.sqrt(1. - lam)\n","    cut_w = int(W * cut_rat)\n","    cut_h = int(H * cut_rat)\n","\n","    # uniform\n","    cx = np.random.randint(W // 4, W - W // 4)\n","    cy = np.random.randint(H // 4, H - H // 4)\n","\n","    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n","    bby1 = np.clip(cy - cut_h // 2, 0, H)\n","    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n","    bby2 = np.clip(cy + cut_h // 2, 0, H)\n","\n","    return bbx1, bby1, bbx2, bby2\n","\n","def cutmix(x, y):\n","    lam = np.random.beta(0.8, 0.8)\n","    indices = torch.randperm(x.shape[0])\n","    \n","    shuffled_x = x[indices]\n","    shuffled_y = y[indices]\n","  \n","    bbx1, bby1, bbx2, bby2 = rand_bbox(x.shape, lam)\n","    x[:, :, bbx1:bbx2, bby1:bby2] = shuffled_x[:, :, bbx1:bbx2, bby1:bby2]\n","    # adjust lambda to exactly match pixel ratio\n","    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.shape[-1] * x.shape[-2]))\n","    new_y = y * lam + shuffled_y * (1 - lam)\n"," \n","    #plt.imshow(x[0].permute(1, 2, 0) / 2 + 0.5)\n","    #plt.show()\n","\n","    return x, new_y"]},{"cell_type":"markdown","metadata":{},"source":["### Cutout"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T22:45:18.982212Z","iopub.status.busy":"2024-05-19T22:45:18.981909Z","iopub.status.idle":"2024-05-19T22:45:18.992150Z","shell.execute_reply":"2024-05-19T22:45:18.991189Z","shell.execute_reply.started":"2024-05-19T22:45:18.982188Z"},"trusted":true},"outputs":[],"source":["def cutout(x, y):\n","    lam = np.random.beta(0.8, 0.8)\n","    bbx1, bby1, bbx2, bby2 = rand_bbox(x.shape, lam)\n","    \n","    x[:, :, bbx1:bbx2, bby1:bby2] = 0\n","    \n","    return x, y"]},{"cell_type":"markdown","metadata":{},"source":["### FMix"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T22:45:18.996050Z","iopub.status.busy":"2024-05-19T22:45:18.995696Z","iopub.status.idle":"2024-05-19T22:45:19.006511Z","shell.execute_reply":"2024-05-19T22:45:19.005587Z","shell.execute_reply.started":"2024-05-19T22:45:18.996025Z"},"trusted":true},"outputs":[],"source":["def fmix(x, y):\n","    new_x, index, lam = FMix(size = x.shape[2 :])(x)\n","    new_y = y * lam + y[index] * (1 - lam)\n","    \n","    return new_x, new_y"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T22:45:19.008369Z","iopub.status.busy":"2024-05-19T22:45:19.007781Z","iopub.status.idle":"2024-05-19T22:45:19.016310Z","shell.execute_reply":"2024-05-19T22:45:19.015516Z","shell.execute_reply.started":"2024-05-19T22:45:19.008336Z"},"trusted":true},"outputs":[],"source":["augmentation_functions = {'mixup': mixup, 'cutmix': cutmix, 'cutout': cutout, 'fmix': fmix}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T22:45:19.017617Z","iopub.status.busy":"2024-05-19T22:45:19.017337Z","iopub.status.idle":"2024-05-19T22:45:19.027752Z","shell.execute_reply":"2024-05-19T22:45:19.026768Z","shell.execute_reply.started":"2024-05-19T22:45:19.017593Z"},"trusted":true},"outputs":[],"source":["augment_prob = 0.5\n","\n","def collate_fn(batch):\n","    x = torch.stack([sample[0] for sample in batch])\n","    y = torch.stack([nn.functional.one_hot(torch.tensor(sample[1]), num_classes = num_classes).float() for sample in batch])\n","    \n","    if online_augmentation_function is not None:\n","        p = np.random.rand()\n","        if p < augment_prob:\n","            new_x, new_y = augmentation_functions[online_augmentation_function](x, y)\n","        else:\n","            new_x, new_y = x, y\n","    else:\n","        new_x, new_y = x, y\n","\n","    return new_x, new_y"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T22:45:19.030755Z","iopub.status.busy":"2024-05-19T22:45:19.030509Z","iopub.status.idle":"2024-05-19T22:46:28.834155Z","shell.execute_reply":"2024-05-19T22:46:28.832785Z","shell.execute_reply.started":"2024-05-19T22:45:19.030734Z"},"trusted":true},"outputs":[],"source":["# DATASET_DIR = '/kaggle/input/face-expression-recognition-dataset/images'\n","DATASET_DIR = '/kaggle/input/stargan-fer-augmented/images'\n","\n","train = torchvision.datasets.ImageFolder(os.path.join(DATASET_DIR, 'train'), transform_images)\n","val = torchvision.datasets.ImageFolder(os.path.join(DATASET_DIR, 'validation'), transform_images)\n","\n","test = val\n","\n","#hflip_aug = FlipAugment(train, horizontal = True)\n","#vflip_aug = FlipAugment(train, horizontal = False)\n","\n","print(train.classes)\n","print(test.classes)\n","print(val.classes)\n","\n","assert train.classes == test.classes and test.classes == val.classes\n","\n","num_to_class = {i : c for i, c in enumerate(train.classes)}\n","\n","#final_train_set = torch.utils.data.ConcatDataset([train, hflip_aug, vflip_aug])\n","final_train_set = train\n","train_data = torch.utils.data.DataLoader(final_train_set, batch_size = batch_size, shuffle = True, collate_fn = collate_fn)\n","test_data = torch.utils.data.DataLoader(test, batch_size = batch_size)\n","val_data = torch.utils.data.DataLoader(val, batch_size = batch_size)\n","\n","print(next(iter(train_data))[0][0].min())\n","\n","optim = Adam(model.parameters(), lr = learning_rate)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","train_losses, test_losses, scores = train_network(model, optim, criterion, train_data, val_data, num_epochs)\n","\n","df = pd.DataFrame({'train loss': train_losses, 'dev loss': test_losses})\n","df.to_csv('losses.csv', sep = ',', index = False)\n","sns.lineplot(df, dashes = False)\n","plt.show()\n","\n","df = pd.DataFrame(scores)\n","df.to_csv('dev_scores.csv', sep = ',', index = False)\n","avg_df = pd.DataFrame()\n","avg_df['Accuracy'] = df['Accuracy']\n","avg_df['Accuracy-2'] = df['Accuracy-2']\n","metrics = ['Precision', 'Recall', 'F1']\n","for m in metrics:\n","    s = None\n","    for label in range(num_classes):\n","        if s is None:\n","            s = df[m + ' ' + num_to_class[label]]\n","        else:\n","            s = s + df[m + ' ' + num_to_class[label]]\n","    s = s / num_classes\n","    avg_df[m] = s\n","    \n","sns.lineplot(avg_df, dashes = False)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T22:46:32.881251Z","iopub.status.busy":"2024-05-19T22:46:32.880878Z","iopub.status.idle":"2024-05-19T22:47:04.226657Z","shell.execute_reply":"2024-05-19T22:47:04.225739Z","shell.execute_reply.started":"2024-05-19T22:46:32.881219Z"},"trusted":true},"outputs":[],"source":["model.eval()\n","\n","table = {'Accuracy': [], 'Accuracy-2': []}\n","for label in range(num_classes):\n","    table['Precision ' + num_to_class[label]] = []\n","    table['Recall ' + num_to_class[label]] = []\n","    table['F1 ' + num_to_class[label]] = []\n","\n","golden, outputs, outputs_raw = predict_multiple(model, test_data)\n","        \n","prfs = precision_recall_fscore_support(golden, outputs, zero_division = 0)\n","\n","table['Accuracy'].append(accuracy_score(golden, outputs))\n","table['Accuracy-2'].append(top_k_accuracy_score(golden, outputs_raw))\n","for i, label in enumerate(range(num_classes)):\n","    table['Precision ' + num_to_class[label]].append(prfs[0][i])\n","    table['Recall ' + num_to_class[label]].append(prfs[1][i])\n","    table['F1 ' + num_to_class[label]].append(prfs[2][i])\n","\n","df = pd.DataFrame(table)\n","df.to_csv('test_scores.csv', sep = ',', index = False)\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T22:47:17.481564Z","iopub.status.busy":"2024-05-19T22:47:17.481203Z","iopub.status.idle":"2024-05-19T22:47:17.561696Z","shell.execute_reply":"2024-05-19T22:47:17.560958Z","shell.execute_reply.started":"2024-05-19T22:47:17.481534Z"},"trusted":true},"outputs":[],"source":["if not HF_MODEL:\n","    torch.save(model.state_dict(), model_name + '_full.pth')\n","    model.reset_classifier(0)\n","    torch.save(model.state_dict(), model_name + '_feats.pth')\n","else:\n","    torch.save(model.state_dict(), model_name.split('/')[1] + '_full.pth')\n","    model.classifier = torch.nn.Identity()\n","    torch.save(model.state_dict(), model_name.split('/')[1] + '_feats.pth')"]},{"cell_type":"markdown","metadata":{},"source":["### OOD"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T22:47:41.648226Z","iopub.status.busy":"2024-05-19T22:47:41.647611Z","iopub.status.idle":"2024-05-19T22:51:49.773433Z","shell.execute_reply":"2024-05-19T22:51:49.772426Z","shell.execute_reply.started":"2024-05-19T22:47:41.648188Z"},"trusted":true},"outputs":[],"source":["OOD_PARAMS_DIR = 'ood_params'\n","\n","if not os.path.exists(OOD_PARAMS_DIR):\n","    os.makedirs(OOD_PARAMS_DIR)\n","    \n","ood_data = torch.utils.data.DataLoader(torch.utils.data.ConcatDataset([final_train_set, val]), batch_size = 32)\n","\n","if not HF_MODEL:\n","    latent_feats_dim = model.forward(torch.randn(1, 3, 224, 224).to(device)).shape[-1]\n","else:\n","    latent_feats_dim = model.forward(torch.randn(1, 3, 224, 224).to(device)).logits.shape[-1]\n","\n","# prepare mahalanobis distance params\n","mean_feature_maps = torch.zeros((num_classes, latent_feats_dim)).to(device)\n","mean_feature_map_0 = torch.zeros(latent_feats_dim).to(device)\n","Nk = torch.zeros(num_classes).to(device)\n","covar = torch.zeros((latent_feats_dim, latent_feats_dim)).to(device)\n","covar_0 = torch.zeros((latent_feats_dim, latent_feats_dim)).to(device)\n","\n","def save_tensor(x, file_path):\n","    if len(x.shape) == 1:\n","        x = x[None, :]\n","    \n","    with open(file_path, \"w\") as f:\n","        f.write(f\"{x.shape[0]}\\n{x.shape[1]}\\n\")\n","        for i in range(x.shape[0]):\n","            for j in range(x.shape[1]):\n","                f.write(f\"{x[i, j]}\\n\")\n","\n","with torch.no_grad():\n","    # Calculate mean feature maps\n","    print(\"Calculating mean feature maps...\")\n","    for batch, label in ood_data:\n","        batch = batch.to(device)\n","        \n","        if not HF_MODEL:\n","            z = model(batch)\n","        else:\n","            z = model(batch).logits\n","        # print(z.shape)\n","        for feature_map, label_num in zip(z, label):\n","            mean_feature_maps[label_num] += feature_map\n","            Nk[label_num] += 1\n","    \n","    mean_feature_map_0 = torch.sum(mean_feature_maps, dim = 0) / torch.sum(Nk)\n","    mean_feature_maps = (mean_feature_maps.T / Nk).T\n","    torch.save(mean_feature_map_0, \"ood_params/mean_feature_map_0.pt\")\n","    save_tensor(mean_feature_map_0, \"ood_params/mean_feature_map_0.matrix\")\n","    torch.save(mean_feature_maps, \"ood_params/mean_feature_maps.pt\")\n","    save_tensor(mean_feature_maps, \"ood_params/mean_feature_maps.matrix\")\n","    \n","    # Calculate covariance matrices\n","    print(\"Calculating covariance matrices\")\n","    for batch, label in ood_data:\n","        batch = batch.to(device)\n","        \n","        if not HF_MODEL:\n","            z = model(batch)\n","        else:\n","            z = model(batch).logits\n","        for feature_map, label_num in zip(z, label):\n","            feature_map_adjusted_0 = (feature_map - mean_feature_map_0)[None, :]\n","            feature_map_adjusted = (feature_map - mean_feature_maps[label_num])[None, :]\n","            covar_0 += feature_map_adjusted_0.T @ feature_map_adjusted_0\n","            covar += feature_map_adjusted.T @ feature_map_adjusted\n","    \n","    covar_0 = covar_0 / torch.sum(Nk)\n","    covar = covar / torch.sum(Nk)\n","    torch.save(torch.linalg.pinv(covar_0.cpu()), \"ood_params/covar_0_inverse.pt\")\n","    save_tensor(torch.linalg.pinv(covar_0.cpu()), \"ood_params/covar_0_inverse.matrix\")\n","    torch.save(torch.linalg.pinv(covar.cpu()), \"ood_params/covar_inverse.pt\")\n","    save_tensor(torch.linalg.pinv(covar.cpu()), \"ood_params/covar_inverse.matrix\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T22:51:57.488787Z","iopub.status.busy":"2024-05-19T22:51:57.487719Z","iopub.status.idle":"2024-05-19T22:51:57.558008Z","shell.execute_reply":"2024-05-19T22:51:57.557065Z","shell.execute_reply.started":"2024-05-19T22:51:57.488745Z"},"trusted":true},"outputs":[],"source":["summary(model, input_size=(1, 3, 224, 224))"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":99505,"sourceId":234911,"sourceType":"datasetVersion"},{"datasetId":5026253,"sourceId":8438130,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}

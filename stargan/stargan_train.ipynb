{"cells":[{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2021-06-15T09:30:31.761379Z","iopub.status.busy":"2021-06-15T09:30:31.761052Z","iopub.status.idle":"2021-06-15T09:30:31.766331Z","shell.execute_reply":"2021-06-15T09:30:31.764896Z","shell.execute_reply.started":"2021-06-15T09:30:31.761352Z"}},"source":["### Import Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T22:44:55.038260Z","iopub.status.busy":"2024-05-14T22:44:55.037901Z","iopub.status.idle":"2024-05-14T22:45:05.897928Z","shell.execute_reply":"2024-05-14T22:45:05.896747Z","shell.execute_reply.started":"2024-05-14T22:44:55.038163Z"},"trusted":true},"outputs":[],"source":["!pip install torchinfo\n","import pandas as pd\n","import numpy as np\n","import itertools\n","import glob\n","import os\n","from tqdm.notebook import tqdm\n","from torchinfo import summary\n","\n","import torchvision.transforms as transforms\n","from torchvision.utils import save_image\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset\n","from torchvision import datasets\n","from torch.autograd import Variable\n","import torch.autograd as autograd\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch\n","\n","LOAD_FROM_CHECKPOINT = True\n","CHECKPOINT_ROOT = '/kaggle/input/stargan-checkpoint/saved_models'"]},{"cell_type":"markdown","metadata":{},"source":["### Initial Setting"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T22:45:05.900254Z","iopub.status.busy":"2024-05-14T22:45:05.899831Z","iopub.status.idle":"2024-05-14T22:45:05.907381Z","shell.execute_reply":"2024-05-14T22:45:05.906158Z","shell.execute_reply.started":"2024-05-14T22:45:05.900204Z"},"trusted":true},"outputs":[],"source":["# ---------\n","# training\n","# ---------\n","epoch = 0 # epoch to start training from\n","n_epochs = 25 # number of epochs of training (suggested default : 200)\n","batch_size = 16 # size of the batches. suggested.\n","lr = 0.0002 # adam : learning rate\n","b1 = 0.5 # adam : decay of first order momentum of gradient\n","b2 = 0.999 # adam : decay of first order momentum of gradient\n","\n","# ---------\n","# image data\n","# ---------\n","root = '/kaggle/input/face-expression-recognition-dataset/images'\n","img_height = 128 # size of image height\n","img_width = 128 # size of image width\n","channels = 3 # number of image channels\n","\n","# ---------\n","# modeling\n","# ---------\n","residual_blocks = 6 # number of residual blocks in generator\n","n_critic = 5 # number of training iterations for WGAN discriminator\n","# selected_attrs = ['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Male', 'Young'] # selected attributes for the CelebA dataset\n","selected_attrs = ['angry', 'disgusted', 'fearful', 'happy', 'neutral', 'sad', 'surprised']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T22:45:05.909988Z","iopub.status.busy":"2024-05-14T22:45:05.909542Z","iopub.status.idle":"2024-05-14T22:45:07.005842Z","shell.execute_reply":"2024-05-14T22:45:07.004584Z","shell.execute_reply.started":"2024-05-14T22:45:05.909944Z"},"trusted":true},"outputs":[],"source":["# number of cpu (in kaggle server - Accelerator : GPU)\n","!cat /proc/cpuinfo | grep processor"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T22:45:07.008463Z","iopub.status.busy":"2024-05-14T22:45:07.008123Z","iopub.status.idle":"2024-05-14T22:45:07.013411Z","shell.execute_reply":"2024-05-14T22:45:07.012292Z","shell.execute_reply.started":"2024-05-14T22:45:07.008429Z"},"trusted":true},"outputs":[],"source":["n_cpu = 2 # number of cpu threads to use during batch generation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T22:45:07.015110Z","iopub.status.busy":"2024-05-14T22:45:07.014743Z","iopub.status.idle":"2024-05-14T22:45:07.029204Z","shell.execute_reply":"2024-05-14T22:45:07.027973Z","shell.execute_reply.started":"2024-05-14T22:45:07.015074Z"},"trusted":true},"outputs":[],"source":["c_dim = len(selected_attrs) # number of input-attributes\n","c_dim"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T22:45:07.030895Z","iopub.status.busy":"2024-05-14T22:45:07.030565Z","iopub.status.idle":"2024-05-14T22:45:07.041261Z","shell.execute_reply":"2024-05-14T22:45:07.040343Z","shell.execute_reply.started":"2024-05-14T22:45:07.030861Z"},"trusted":true},"outputs":[],"source":["img_shape = (channels, img_height, img_width) # set image shape for pytorch\n","img_shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T22:45:07.043102Z","iopub.status.busy":"2024-05-14T22:45:07.042683Z","iopub.status.idle":"2024-05-14T22:45:07.097671Z","shell.execute_reply":"2024-05-14T22:45:07.096593Z","shell.execute_reply.started":"2024-05-14T22:45:07.043058Z"},"trusted":true},"outputs":[],"source":["cuda = torch.cuda.is_available()\n","cuda"]},{"cell_type":"markdown","metadata":{},"source":["### Define Generator"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T22:45:07.101031Z","iopub.status.busy":"2024-05-14T22:45:07.100667Z","iopub.status.idle":"2024-05-14T22:45:07.109555Z","shell.execute_reply":"2024-05-14T22:45:07.108562Z","shell.execute_reply.started":"2024-05-14T22:45:07.100995Z"},"trusted":true},"outputs":[],"source":["class ResidualBlock(nn.Module):\n","    def __init__(self, in_features):\n","        super(ResidualBlock, self).__init__()\n","        \n","        conv_block = [\n","            nn.Conv2d(in_features, in_features, 3, stride=1, padding=1, bias=False),\n","            nn.InstanceNorm2d(in_features, affine=True, track_running_stats=True),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(in_features, in_features, 3, stride=1, padding=1, bias=False),\n","            nn.InstanceNorm2d(in_features, affine=True, track_running_stats=True)\n","        ]\n","        \n","        self.conv_block = nn.Sequential(*conv_block) # list-unpacking\n","    \n","    def forward(self, x):\n","        return x + self.conv_block(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T22:45:07.112063Z","iopub.status.busy":"2024-05-14T22:45:07.111697Z","iopub.status.idle":"2024-05-14T22:45:07.127571Z","shell.execute_reply":"2024-05-14T22:45:07.126602Z","shell.execute_reply.started":"2024-05-14T22:45:07.112031Z"},"trusted":true},"outputs":[],"source":["class GeneratorResNet(nn.Module):\n","    def __init__(self, img_shape=(3,128,128), res_blocks=9, c_dim=5):\n","        super(GeneratorResNet, self).__init__()\n","        channels, img_size, _ = img_shape\n","        \n","        # Initial convolution block\n","        model = [\n","            nn.Conv2d(channels+c_dim, 64, 7, stride=1, padding=3, bias=False), # in_channels = channels+c_dim (domain added in channel)\n","            nn.InstanceNorm2d(64, affine=True, track_running_stats=True),\n","            nn.ReLU(inplace=True)\n","        ]\n","        \n","        # Downsampling\n","        curr_dim = 64\n","        for _ in range(2):\n","            model += [\n","                nn.Conv2d(curr_dim, curr_dim*2, 4, stride=2, padding=1, bias=False), \n","                nn.InstanceNorm2d(curr_dim*2, affine=True, track_running_stats=True),\n","                nn.ReLU(inplace=True)\n","            ]\n","            curr_dim *= 2 # 64->128\n","        \n","        # Residual blocks\n","        for _ in range(res_blocks): # 9-loop\n","            model += [ResidualBlock(curr_dim)] # 128->128\n","        \n","        # Upsampling\n","        for _ in range(2):\n","            model += [\n","                nn.ConvTranspose2d(curr_dim, curr_dim//2, 4, stride=2, padding=1, bias=False),\n","                nn.InstanceNorm2d(curr_dim//2, affine=True, track_running_stats=True),\n","                nn.ReLU(inplace=True),\n","            ]\n","            curr_dim = curr_dim//2 # 128->64\n","            \n","        # Output layer\n","        model += [\n","            nn.Conv2d(curr_dim, channels, 7, stride=1, padding=3), # 64 -> 3 (return RGB Image)\n","            nn.Tanh() # -1 < tanh(x) < 1\n","        ]\n","        \n","        self.model = nn.Sequential(*model) # Unpack the list of layers \n","    \n","    def forward(self, x, c):\n","#         print(x.shape)\n","#         print(c.shape)\n","        c = c.view(c.size(0), c.size(1), 1, 1)\n","        c = c.repeat(1, 1, x.size(2), x.size(3))\n","        x = torch.cat((x,c), 1) # get image(x) and domain(c)\n","#         print(x.shape)\n","        return self.model(x)"]},{"cell_type":"markdown","metadata":{},"source":["### Define Discriminator"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T22:45:07.129404Z","iopub.status.busy":"2024-05-14T22:45:07.128988Z","iopub.status.idle":"2024-05-14T22:45:07.141498Z","shell.execute_reply":"2024-05-14T22:45:07.140461Z","shell.execute_reply.started":"2024-05-14T22:45:07.129344Z"},"trusted":true},"outputs":[],"source":["class Discriminator(nn.Module):\n","    def __init__(self, img_shape=(3,128,128), c_dim=5, n_strided=6):\n","        super(Discriminator, self).__init__()\n","        channels, img_size, _ = img_shape\n","        \n","        def discriminator_block(in_filters, out_filters):\n","            \"\"\"Returns downsampling layers of each discriminator block\"\"\"\n","            layers = [\n","                nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1), \n","                nn.LeakyReLU(0.01)\n","            ]\n","            return layers\n","        \n","        layers = discriminator_block(channels, 64)\n","        curr_dim = 64\n","        for _ in range(n_strided-1):\n","            layers.extend(discriminator_block(curr_dim, curr_dim*2))\n","            curr_dim *= 2\n","            \n","        self.model = nn.Sequential(*layers)\n","        \n","        # Output 1 : PatchGAN\n","        self.out1 = nn.Conv2d(curr_dim, 1, 3, padding=1, bias=False)\n","        # Output 2 : Class prediction\n","        kernel_size = img_size//(2**n_strided)\n","        self.out2 = nn.Conv2d(curr_dim, c_dim, kernel_size, bias=False)\n","        \n","    def forward(self, img):\n","        feature_repr = self.model(img)\n","        out_adv = self.out1(feature_repr) # real or fake\n","        out_cls = self.out2(feature_repr) # matching-domain\n","        return out_adv, out_cls.view(out_cls.size(0), -1)\n","        "]},{"cell_type":"markdown","metadata":{},"source":["### Define Loss function and Initialize Loss weights"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T22:45:07.143272Z","iopub.status.busy":"2024-05-14T22:45:07.142946Z","iopub.status.idle":"2024-05-14T22:45:07.154781Z","shell.execute_reply":"2024-05-14T22:45:07.153693Z","shell.execute_reply.started":"2024-05-14T22:45:07.143242Z"},"trusted":true},"outputs":[],"source":["# Loss function - Cycle loss\n","criterion_cycle = torch.nn.L1Loss()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T22:45:07.156293Z","iopub.status.busy":"2024-05-14T22:45:07.155971Z","iopub.status.idle":"2024-05-14T22:45:07.164495Z","shell.execute_reply":"2024-05-14T22:45:07.163591Z","shell.execute_reply.started":"2024-05-14T22:45:07.156262Z"},"trusted":true},"outputs":[],"source":["# Loss function - Domain-Class loss\n","def criterion_cls(logit, target):\n","    return F.binary_cross_entropy_with_logits(logit, target, size_average=False) / logit.size(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T22:45:07.166035Z","iopub.status.busy":"2024-05-14T22:45:07.165698Z","iopub.status.idle":"2024-05-14T22:45:07.174452Z","shell.execute_reply":"2024-05-14T22:45:07.173351Z","shell.execute_reply.started":"2024-05-14T22:45:07.165991Z"},"trusted":true},"outputs":[],"source":["# Loss weights (suggested default in paper)\n","lambda_cls = 1\n","lambda_rec = 10\n","lambda_gp = 10"]},{"cell_type":"markdown","metadata":{},"source":["### Initialize Generator and Discriminator"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T22:45:07.176207Z","iopub.status.busy":"2024-05-14T22:45:07.175771Z","iopub.status.idle":"2024-05-14T22:45:07.695301Z","shell.execute_reply":"2024-05-14T22:45:07.694232Z","shell.execute_reply.started":"2024-05-14T22:45:07.176158Z"},"trusted":true},"outputs":[],"source":["generator = GeneratorResNet(img_shape=img_shape, res_blocks=residual_blocks, c_dim=c_dim)\n","discriminator = Discriminator(img_shape=img_shape, c_dim=c_dim)"]},{"cell_type":"markdown","metadata":{},"source":["### GPU Setting"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T22:45:07.696943Z","iopub.status.busy":"2024-05-14T22:45:07.696620Z","iopub.status.idle":"2024-05-14T22:45:12.393450Z","shell.execute_reply":"2024-05-14T22:45:12.392478Z","shell.execute_reply.started":"2024-05-14T22:45:07.696910Z"},"trusted":true},"outputs":[],"source":["if cuda:\n","    generator = generator.cuda()\n","    discriminator = discriminator.cuda()\n","    criterion_cycle.cuda()"]},{"cell_type":"markdown","metadata":{},"source":["### Weight Setting"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T22:45:12.395129Z","iopub.status.busy":"2024-05-14T22:45:12.394809Z","iopub.status.idle":"2024-05-14T22:45:12.400504Z","shell.execute_reply":"2024-05-14T22:45:12.399475Z","shell.execute_reply.started":"2024-05-14T22:45:12.395100Z"},"trusted":true},"outputs":[],"source":["def weights_init_normal(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        torch.nn.init.normal_(m.weight.data, 0.0, 0.02) # reset Conv2d's weight(tensor) with Gaussian Distribution"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T22:45:12.402176Z","iopub.status.busy":"2024-05-14T22:45:12.401772Z","iopub.status.idle":"2024-05-14T22:45:12.418844Z","shell.execute_reply":"2024-05-14T22:45:12.418040Z","shell.execute_reply.started":"2024-05-14T22:45:12.402144Z"},"trusted":true},"outputs":[],"source":["generator.apply(weights_init_normal)\n","discriminator.apply(weights_init_normal);"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T22:45:12.420593Z","iopub.status.busy":"2024-05-14T22:45:12.420216Z","iopub.status.idle":"2024-05-14T22:45:17.060509Z","shell.execute_reply":"2024-05-14T22:45:17.059449Z","shell.execute_reply.started":"2024-05-14T22:45:12.420544Z"},"trusted":true},"outputs":[],"source":["if LOAD_FROM_CHECKPOINT:\n","    checkpoint = torch.load(os.path.join(CHECKPOINT_ROOT, f'StarGAN_checkpoint_{epoch}_epochs.pt'))\n","    generator.load_state_dict(checkpoint['generator_state_dict'])\n","    discriminator.load_state_dict(checkpoint['discriminator_state_dict'])\n","    print(\"LOADED MODELS FROM CHECKPOINT\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T22:45:17.062127Z","iopub.status.busy":"2024-05-14T22:45:17.061816Z","iopub.status.idle":"2024-05-14T22:45:18.034347Z","shell.execute_reply":"2024-05-14T22:45:18.033249Z","shell.execute_reply.started":"2024-05-14T22:45:17.062095Z"},"trusted":true},"outputs":[],"source":["summary(generator, input_data=[torch.rand((1, 3, 128, 128)).cuda(), torch.rand((1, c_dim)).cuda()])"]},{"cell_type":"markdown","metadata":{},"source":["> Read More\n","- [CycleGAN Tutorial : Monet-to-Photo - Step 8. Weight Setting](https://www.kaggle.com/songseungwon/cyclegan-tutorial-monet-to-photo)"]},{"cell_type":"markdown","metadata":{},"source":["### Configure Optimizers"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T22:45:18.036268Z","iopub.status.busy":"2024-05-14T22:45:18.035889Z","iopub.status.idle":"2024-05-14T22:45:18.043314Z","shell.execute_reply":"2024-05-14T22:45:18.042272Z","shell.execute_reply.started":"2024-05-14T22:45:18.036233Z"},"trusted":true},"outputs":[],"source":["if LOAD_FROM_CHECKPOINT:\n","    optimizer_G = checkpoint['optimizer_G']\n","    optimizer_D = checkpoint['optimizer_D']\n","    print(\"LOADED OPTIMIZERS FROM CHECKPOINT\")\n","else:\n","    optimizer_G = torch.optim.Adam(\n","        generator.parameters(),\n","        lr=lr,\n","        betas=(b1,b2)\n","    )\n","    optimizer_D = torch.optim.Adam(\n","        discriminator.parameters(),\n","        lr=lr,\n","        betas=(b1,b2)\n","    )"]},{"cell_type":"markdown","metadata":{},"source":["### Set transforms"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T22:45:18.045156Z","iopub.status.busy":"2024-05-14T22:45:18.044823Z","iopub.status.idle":"2024-05-14T22:45:18.053745Z","shell.execute_reply":"2024-05-14T22:45:18.052734Z","shell.execute_reply.started":"2024-05-14T22:45:18.045112Z"},"trusted":true},"outputs":[],"source":["processor = transforms.Normalize(mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5))\n","inverse_processor = transforms.Normalize(mean = (-1.0, -1.0, -1.0), std = (2.0, 2.0, 2.0))\n","\n","def transform_images(x):\n","    x = x.resize((128, 128))\n","    x = transforms.ToTensor()(x)\n","#     x = transforms.RandomRotation(15)(x)\n","    x = transforms.RandomHorizontalFlip(0.25)(x)\n","#     x = transforms.RandomVerticalFlip(0.25)(x)\n","    x = processor(x)\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T22:45:18.055343Z","iopub.status.busy":"2024-05-14T22:45:18.055002Z","iopub.status.idle":"2024-05-14T22:45:18.063181Z","shell.execute_reply":"2024-05-14T22:45:18.062226Z","shell.execute_reply.started":"2024-05-14T22:45:18.055313Z"},"trusted":true},"outputs":[],"source":["def collate_fn(batch):\n","    x = torch.stack([sample[0] for sample in batch])\n","    y = torch.stack([nn.functional.one_hot(torch.tensor(sample[1]), num_classes = c_dim).float() for sample in batch])\n","    #p = np.random.rand()\n","    #if p < augment_prob:\n","    #   new_x, new_y = fmix(x, y)\n","    #else:\n","    new_x, new_y = x, y\n","    \n","    # return x, y\n","    return new_x, new_y"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T22:45:18.067557Z","iopub.status.busy":"2024-05-14T22:45:18.067169Z","iopub.status.idle":"2024-05-14T22:45:40.782850Z","shell.execute_reply":"2024-05-14T22:45:40.781659Z","shell.execute_reply.started":"2024-05-14T22:45:18.067504Z"},"trusted":true},"outputs":[],"source":["train = datasets.ImageFolder(os.path.join(root, 'train'), transform_images)\n","test = datasets.ImageFolder(os.path.join(root, 'validation'), transform_images)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T22:45:40.785496Z","iopub.status.busy":"2024-05-14T22:45:40.784982Z","iopub.status.idle":"2024-05-14T22:45:40.791059Z","shell.execute_reply":"2024-05-14T22:45:40.789995Z","shell.execute_reply.started":"2024-05-14T22:45:40.785448Z"},"trusted":true},"outputs":[],"source":["train_data = DataLoader(train, batch_size = batch_size, shuffle = True, collate_fn = collate_fn)\n","test_data = DataLoader(test, batch_size = batch_size, shuffle = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T22:45:40.792862Z","iopub.status.busy":"2024-05-14T22:45:40.792521Z","iopub.status.idle":"2024-05-14T22:45:40.807100Z","shell.execute_reply":"2024-05-14T22:45:40.806049Z","shell.execute_reply.started":"2024-05-14T22:45:40.792829Z"},"trusted":true},"outputs":[],"source":["num_to_class = {i:c for (i, c) in enumerate(train.classes)}\n","class_to_num = {c:i for (i, c) in enumerate(train.classes)}\n","num_to_class"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T22:45:40.808898Z","iopub.status.busy":"2024-05-14T22:45:40.808478Z","iopub.status.idle":"2024-05-14T22:45:41.056457Z","shell.execute_reply":"2024-05-14T22:45:41.055429Z","shell.execute_reply.started":"2024-05-14T22:45:40.808854Z"},"trusted":true},"outputs":[],"source":["plt.imshow(inverse_processor(next(iter(train_data))[0][2]).permute(1,2,0))\n","plt.axis('off')"]},{"cell_type":"markdown","metadata":{},"source":["### Define Gradient Penalty Function"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T22:45:41.058449Z","iopub.status.busy":"2024-05-14T22:45:41.057997Z","iopub.status.idle":"2024-05-14T22:45:41.063347Z","shell.execute_reply":"2024-05-14T22:45:41.062210Z","shell.execute_reply.started":"2024-05-14T22:45:41.058402Z"},"trusted":true},"outputs":[],"source":["# Tensor type\n","Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T22:45:41.065146Z","iopub.status.busy":"2024-05-14T22:45:41.064783Z","iopub.status.idle":"2024-05-14T22:45:41.074448Z","shell.execute_reply":"2024-05-14T22:45:41.073298Z","shell.execute_reply.started":"2024-05-14T22:45:41.065112Z"},"trusted":true},"outputs":[],"source":["def compute_gradient_penalty(D, real_samples, fake_samples):\n","    \"\"\"Calculates the gradient penalty loss for WGAN-GP\"\"\"\n","    # Random weight term for interpolation between real and fake samples\n","    alpha = Tensor(np.random.random((real_samples.size(0),1,1,1)))\n","    # Get random interpolation between real and fake samples\n","    interpolates = (alpha*real_samples + ((1-alpha)*fake_samples)).requires_grad_(True) # requires_grad inplace\n","    d_interpolates, _ = D(interpolates) # adv_info, cls_info = discriminator(interpolated image)\n","    fake = Tensor(np.ones(d_interpolates.shape))\n","    # Get gradient w.r.t interpolates\n","    gradients = autograd.grad(\n","        outputs=d_interpolates,\n","        inputs=interpolates,\n","        grad_outputs=fake,\n","        create_graph=True,\n","        retain_graph=True,\n","        only_inputs=True\n","    )[0]\n","    gradients = gradients.view(gradients.size(0),-1)\n","    gradient_penalty = ((gradients.norm(2, dim=1)-1)**2).mean()\n","    return gradient_penalty"]},{"cell_type":"markdown","metadata":{},"source":["### Define function to get sample images with input label list"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T22:48:57.723967Z","iopub.status.busy":"2024-05-14T22:48:57.723627Z","iopub.status.idle":"2024-05-14T22:48:57.734431Z","shell.execute_reply":"2024-05-14T22:48:57.733401Z","shell.execute_reply.started":"2024-05-14T22:48:57.723938Z"},"trusted":true},"outputs":[],"source":["def sample_images():\n","    \"\"\"Show a generated sample of domain translations\"\"\"\n","    val_imgs, val_labels = next(iter(test_data))\n","    val_imgs = val_imgs.type(Tensor)\n","    val_labels = val_labels.type(Tensor)\n","    img_samples = None\n","    for i in range(10):\n","        img, label = val_imgs[i], val_labels[i]\n","        # Repeat for number of label changes\n","        imgs = img.repeat(c_dim, 1, 1, 1) # c_dim is number of domains (5)\n","        labels = [*range(c_dim)]\n","        labels = nn.functional.one_hot(torch.Tensor(labels).long(), num_classes = c_dim).float()\n","        \n","        labels = labels.cuda() if cuda else labels\n","        \n","        # Generate translations\n","        gen_imgs = generator(imgs, labels)\n","        # Concatenate images by width\n","        gen_imgs = torch.cat([x for x in gen_imgs.data], -1)\n","        img_sample = torch.cat((img.data, gen_imgs), -1)\n","        img_sample = inverse_processor(img_sample)\n","        # Add as row to generated samples\n","        img_samples = img_sample if img_samples is None else torch.cat((img_samples, img_sample),-2)\n","    plt.figure(figsize=(16,32))\n","    plt.imshow(img_samples.permute(1,2,0).detach().cpu())\n","    plt.axis('off')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T22:49:00.038532Z","iopub.status.busy":"2024-05-14T22:49:00.038158Z","iopub.status.idle":"2024-05-14T22:49:01.961923Z","shell.execute_reply":"2024-05-14T22:49:01.960605Z","shell.execute_reply.started":"2024-05-14T22:49:00.038501Z"},"trusted":true},"outputs":[],"source":["sample_images()"]},{"cell_type":"markdown","metadata":{},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-14T22:45:41.317775Z","iopub.status.idle":"2024-05-14T22:45:41.318267Z"},"trusted":true},"outputs":[],"source":["# import warnings\n","# warnings.filterwarnings(action='ignore')\n","\n","generator_losses = []\n","discriminator_losses = []\n","initial_epoch = epoch\n","\n","for epoch in range(epoch, n_epochs):\n","    # data_loader\n","    generator_epoch_losses = []\n","    discriminator_epoch_losses = []\n","    for i, (imgs, labels) in enumerate(tqdm(train_data)):\n","        # Model inputs\n","        imgs = imgs.type(Tensor)\n","        labels = labels.type(Tensor)\n","        \n","        # Sample labels as generator inputs\n","#         sampled_c = Tensor(np.random.randint(0, 2, (imgs.size(0), c_dim)))\n","        sampled_c = F.one_hot(torch.Tensor(np.random.randint(0, c_dim, imgs.size(0))).long(), c_dim).float()\n","        if cuda:\n","            sampled_c = sampled_c.cuda()\n","        # Generate fake batch of images\n","        fake_imgs = generator(imgs, sampled_c)\n","        \n","# -------------------\n","# Train Discriminator\n","# -------------------\n","        optimizer_D.zero_grad()\n","    \n","        # Real images\n","        real_validity, pred_cls = discriminator(imgs)\n","        # Fake images\n","        fake_validity, _ = discriminator(fake_imgs.detach())\n","        # Gradient penalty\n","        gradient_penalty = compute_gradient_penalty(discriminator, imgs.data, fake_imgs.data)\n","        # Adversarial loss\n","        loss_D_adv = -torch.mean(real_validity) + torch.mean(fake_validity) + lambda_gp*gradient_penalty\n","        # Classification loss\n","        loss_D_cls = criterion_cls(pred_cls, labels)\n","        # Total loss\n","        loss_D = loss_D_adv + lambda_cls*loss_D_cls\n","        \n","        discriminator_epoch_losses.append(loss_D.item())\n","        \n","        loss_D.backward()\n","        optimizer_D.step()\n","        \n","        optimizer_G.zero_grad()\n","        \n","        # Every n_critic times update generator\n","        if i % n_critic == 0: # n_critic : 5\n","\n","        # -------------------\n","        # Train Generator\n","        # -------------------\n","            # Translate and reconstruct image\n","            gen_imgs = generator(imgs, sampled_c)\n","            recov_imgs = generator(gen_imgs, labels)\n","            # Discriminator evaluates translated image\n","            fake_validity, pred_cls = discriminator(gen_imgs)\n","            # Adversarial loss\n","            loss_G_adv = -torch.mean(fake_validity)\n","            # Classification loss\n","            loss_G_cls = criterion_cls(pred_cls, sampled_c)\n","            # Reconstruction loss\n","            loss_G_rec = criterion_cycle(recov_imgs, imgs)\n","            # Total loss\n","            loss_G = loss_G_adv + lambda_cls*loss_G_cls + lambda_rec*loss_G_rec\n","            \n","            generator_epoch_losses.append(loss_G.item())\n","            \n","            loss_G.backward()\n","            optimizer_G.step()\n","            \n","        # -------------------\n","        # Show Progress\n","        # -------------------\n","        if (i+1) % 50 == 0: \n","            print(\"[Epoch %d/%d] [Batch %d/%d] [D adv: %f, aux: %f] [G loss: %f, adv: %f, aux: %f, cycle: %f]\"\n","                % (\n","                    epoch+1, n_epochs,                     # Epoch\n","                    i+1,len(train_data),                   # Batch\n","                    loss_D_adv.item(),loss_D_cls.item(),   # D loss\n","                    loss_G.item(),loss_G_adv.item(),       # G loss (total, adv)\n","                    loss_G_cls.item(),loss_G_rec.item(),   # G loss (cls, cycle)\n","                ))\n","    generator_losses.append(np.mean(generator_epoch_losses))\n","    discriminator_losses.append(np.mean(discriminator_epoch_losses))\n","    sample_images()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-14T22:45:41.319339Z","iopub.status.idle":"2024-05-14T22:45:41.319835Z"},"trusted":true},"outputs":[],"source":["print(generator_losses)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-14T22:45:41.320962Z","iopub.status.idle":"2024-05-14T22:45:41.321471Z"},"trusted":true},"outputs":[],"source":["print(discriminator_losses)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-14T22:45:41.322545Z","iopub.status.idle":"2024-05-14T22:45:41.323018Z"},"trusted":true},"outputs":[],"source":["plt.plot(generator_losses)\n","plt.title(\"Generator Losses\")\n","plt.xlabel(\"Epoch\")\n","plt.xticks([*range(initial_epoch, n_epochs, 5)])\n","plt.ylabel(\"Loss\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-14T22:45:41.324174Z","iopub.status.idle":"2024-05-14T22:45:41.324678Z"},"trusted":true},"outputs":[],"source":["plt.plot(discriminator_losses)\n","plt.title(\"Discriminator Losses\")\n","plt.xlabel(\"Epoch\")\n","plt.xticks([*range(initial_epoch, n_epochs, 5)])\n","plt.ylabel(\"Loss\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-14T22:45:41.325592Z","iopub.status.idle":"2024-05-14T22:45:41.326052Z"},"trusted":true},"outputs":[],"source":["os.makedirs('saved_models', exist_ok = True)\n","\n","checkpoint = {\n","    'generator_state_dict': generator.state_dict(),\n","    'discriminator_state_dict': discriminator.state_dict(),\n","    'optimizer_G': optimizer_G,\n","    'optimizer_D': optimizer_D\n","}\n","\n","torch.save(checkpoint, f'saved_models/StarGAN_checkpoint_{n_epochs}_epochs.pt')\n","torch.save(generator.state_dict(), f'saved_models/StarGAN_generator_{n_epochs}_epochs.pt')"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":99505,"sourceId":234911,"sourceType":"datasetVersion"},{"datasetId":5021561,"sourceId":8431812,"sourceType":"datasetVersion"}],"dockerImageVersionId":30097,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"}},"nbformat":4,"nbformat_minor":4}
